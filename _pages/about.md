---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Hello, my name is Xinxu Wei. I am currently a Ph.D. student in Computer Engineering at Lehigh University, advised by Dr. Yu Zhang and Dr. Lifang He. My research lies at the intersection of machine learning, neuroscience, and medical AI, with a particular focus on brain graph foundation models, self-supervised pre-training, and graph neural networks. I hold dual master‚Äôs degrees in Neuroscience from McGill University and Biomedical Engineering from the University of Electronic Science and Technology of China.



# üî• News
- *2025.05*: &nbsp;üéâüéâ One first-author paper has been accepted by ICML 2025. 
- *2025.01*: &nbsp;üéâüéâ One first-author paper has been accepted by Neural Networks (IF=6.0). 

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Preprint</div><img src='images/nips.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

  [A Brain Graph Foundation Model: Pre-Training and Prompt-Tuning for Any Atlas and Disorder](http://arxiv.org/abs/2506.02044) 

**<u>Xinxu Wei</u>**, Kanhao Zhao, Yong Jiao, Lifang He, Yu Zhang

  NeurIPS 2025 Submission

  [Paper](http://arxiv.org/abs/2506.02044)

- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2025</div><img src='images/icml.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Pre-Training Graph Contrastive Masked Autoencoders are Strong Distillers for EEG](https://icml.cc/virtual/2025/poster/44482)

**<u>Xinxu Wei</u>**, Kanhao Zhao, Yong Jiao, Hua Xie, Lifang He, Yu Zhang

ICML 2025 

[Paper](https://arxiv.org/abs/2411.19230)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Neural Networks</div><img src='images/nn.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Multi-modal
cross-domain self-supervised pre-training for fMRI and EEG fusion](https://www.sciencedirect.com/science/article/pii/S089360802400995X)

**<u>Xinxu Wei</u>**, Kanhao Zhao, Yong Jiao, Hua Xie, Lifang He, Yu Zhang

Neural Networks (IF=6.0)

 [Paper](https://www.sciencedirect.com/science/article/pii/S089360802400995X)

</div>
</div>




<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Expert Systems with Applications</div><img src='images/eswa.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Orientation and Context Entangled Network for Retinal Vessel Segmentation](https://www.sciencedirect.com/science/article/pii/S0957417422024629)

**<u>Xinxu Wei</u>**, Kaifu Yang, Danilo Bzdok, Yongjie Li

Expert Systems with Applications (IF=7.5)

[Paper](https://arxiv.org/abs/2411.19230)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Digital Signal Processing</div><img src='images/dsp.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[DA-DRN: A degradation-aware deep Retinex network for low-light image enhancement](https://www.sciencedirect.com/science/article/pii/S1051200423003512)

**<u>Xinxu Wei</u>**, Xi Lin, Yongjie Li

Digital Signal Processing (IF=2.9) 

[Paper](https://www.sciencedirect.com/science/article/pii/S1051200423003512)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IEEE BigData</div><img src='images/bigdata.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Pneumonia: Attention-Based Contrastive Learning for Class-Imbalanced Pneumonia Lesion Recognition in Chest X-rays](https://ieeexplore.ieee.org/abstract/document/10020283)

**<u>Xinxu Wei</u>**, Xiangke Niu, Xianshi Zhang, Yongjie Li

2022 IEEE International Conference on Big Data (Big Data)

[Paper](https://ieeexplore.ieee.org/abstract/document/10020283)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICANN</div><img src='images/icann.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[TSN-CA: A Two-Stage Network with Channel Attention for Low-Light Image Enhancement](https://link.springer.com/chapter/10.1007/978-3-031-15934-3_24)

**<u>Xinxu Wei</u>**, Xiangke Niu, Xianshi Zhang, Yongjie Li

Artificial Neural Networks and Machine Learning ‚Äì ICANN 2022

[Paper](https://link.springer.com/chapter/10.1007/978-3-031-15934-3_24)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Preprint</div><img src='images/tai.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[TSN-CA: A Two-Stage Network with Channel Attention for Low-Light Image Enhancement](https://arxiv.org/abs/2409.11508)

**<u>Xinxu Wei</u>**, Xi Lin, Yongjie Li

Under Review by IEEE Transactions on Artificial Intelligence (TAI)

[Paper](https://arxiv.org/abs/2409.11508)

</div>
</div>



# üéñ Honors and Awards
- *2023.08* Lehigh University Fellowship. 
- *2022.05* First-Class Scholarship of UESTC. 

# üìñ Educations
- *2023.08 - 2027.01 (now)*, Ph.D., **Lehigh University**, Bethelehem PA, USA
- *2021.08 - 2023.05*, Master of Science (Dual Master Degree), **McGill University**, Montreal, Canada
- *2020.08 - 2023.05*, Master of Engineering, **University of Electronic Science and Technology of China**, Chengdu, China
- *2016.08 - 2020.05*, Bachelor of Engineering, **University of Electronic Science and Technology of China**, Chengdu, China

<!--
# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)
-->

<!--
# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
-->
