---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Hello, my name is Xinxu Wei. I am currently a Ph.D. student in Computer Engineering at Lehigh University, advised by Dr. Yu Zhang and Dr. Lifang He. My research lies at the intersection of machine learning, neuroscience, and medical AI, with a particular focus on brain graph foundation models, self-supervised pre-training, and graph neural networks. I hold dual master‚Äôs degrees in Neuroscience from McGill University and Biomedical Engineering from the University of Electronic Science and Technology of China.



# üî• News
- *2025.05*: &nbsp;üéâüéâ One first-author paper has been accepted by ICML 2025. 
- *2025.01*: &nbsp;üéâüéâ One first-author paper has been accepted by Neural Networks (IF=6.0). 

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Preprint</div><img src='images/nips.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

  [A Brain Graph Foundation Model: Pre-Training and Prompt-Tuning for Any Atlas and Disorder](https://arxiv.org/abs/2406.00000) 

  **Xinxu Wei**, Kanhao Zhao, Yong Jiao, Lifang He, Yu Zhang

  NeurIPS 2025 Submission

  [Paper](https://arxiv.org/pdf/2406.00000.pdf)

- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2025</div><img src='images/icml.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Pre-Training Graph Contrastive Masked Autoencoders are Strong Distillers for EEG](https://icml.cc/virtual/2025/poster/44482)

**Xinxu Wei**, Kanhao Zhao, Yong Jiao, Hua Xie, Lifang He, Yu Zhang

ICML 2025 

[Paper](https://arxiv.org/pdf/2406.00000.pdf)

- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Neural Networks</div><img src='images/nn.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Multi-modal
cross-domain self-supervised pre-training for fMRI and EEG fusion](https://www.sciencedirect.com/science/article/pii/S089360802400995X)

**Xinxu Wei**, Kanhao Zhao, Yong Jiao, Hua Xie, Lifang He, Yu Zhang

ICML 2025 

 [Paper](https://arxiv.org/pdf/2406.00000.pdf)

- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>



# üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìñ Educations
- *2023.08 - 2027.01 (now)*, Ph.D., Lehigh University, Bethelehem PA, USA
- *2021.08 - 2023.05*, Master of Science (Dual Master Degree), McGill University, Montreal, Canada
- *2020.08 - 2023.05*, Master of Engineering, University of Electronic Science and Technology of China, Chengdu, China
- *2016.08 - 2020.05*, Bachelor of Engineering, University of Electronic Science and Technology of China, Chengdu, China

<!--
# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)
-->

<!--
# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
-->
